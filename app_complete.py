"""
YODDA Premium v3.0 COMPLETE - Now using NVIDIA NIM API (OpenAI-compatible)
"""
import os
import uuid
import bcrypt
import jwt
import requests
from datetime import datetime, timedelta
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel
import uvicorn

app = FastAPI(title="YODDA Premium v3.0 COMPLETE", version="3.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)

# Mount builds folder for serving generated files
os.makedirs("builds", exist_ok=True)
app.mount("/builds", StaticFiles(directory="builds"), name="builds")

# ==================== CONFIG ====================
SECRET_KEY = os.getenv("SECRET_KEY", "yodda-premium-secret-key-change-in-production")
NVIDIA_API_KEY = os.getenv("NVIDIA_API_KEY")          # Your nvapi-... key
NVIDIA_API_URL = "https://integrate.api.nvidia.com/v1" # Base URL
DEFAULT_MODEL = "meta/llama-3.1-8b-instruct"           # Change to your preferred model
ADMIN_SETUP_DONE = False
security = HTTPBearer()

# ==================== DATABASE (In-Memory) ====================
users_db = {}
licenses_db = {}
agents_db = {
    "mcp": {"name": "MCP Master", "state": "IDLE", "tasks": 0},
    "planner": {"name": "Planner", "state": "IDLE", "tasks": 0},
    "developer": {"name": "Developer", "state": "IDLE", "tasks": 0},
    "pw": {"name": "P&W Orchestrator", "state": "IDLE", "tasks": 0},
    "watchdog": {"name": "Watchdog", "state": "IDLE", "tasks": 0},
    "debugger": {"name": "Debugger", "state": "IDLE", "tasks": 0},
    "deployer": {"name": "Deployer", "state": "IDLE", "tasks": 0},
    "coordinator": {"name": "Swarm Coordinator", "state": "IDLE", "tasks": 0}
}

PRICING_TIERS = {
    "FREE": {"price": 0, "builds": 3, "description": "3 builds total"},
    "BASIC": {"price": 15, "builds": 20, "description": "20 builds/month (monthly)"},
    "PRO": {"price": 50, "builds": 100, "description": "100 builds/month"},
    "ENTERPRISE": {"price": 149, "builds": -1, "description": "Unlimited (1 year)"},
    "PREMIUM": {"price": 249, "builds": -1, "description": "Lifetime Unlimited", "lifetime": True}
}

GAMMA_THEMES = [
    {"id": "dark-pro", "name": "Dark Professional"},
    {"id": "light-modern", "name": "Light Modern"},
    {"id": "blue-enterprise", "name": "Blue Enterprise"},
    {"id": "vibrant-creative", "name": "Vibrant Creative"},
    {"id": "minimal-zen", "name": "Minimal Zen"},
    {"id": "aurora", "name": "Aurora Borealis"}
]

PLATFORMS = ["web", "desktop", "android", "ios"]

# ==================== MODELS ====================
# (keep all BaseModel classes as before - no change)

# ==================== AUTH HELPERS ====================
# (keep hash_password, verify_password, create_token, verify_token as before)

def validate_api(endpoint: str, key: str) -> bool:
    # NVIDIA is always valid if key is correct â†’ simple check
    return bool(key and key.startswith("nvapi-"))

# ==================== LLM CALL HELPER (NVIDIA NIM) ====================
def call_llm(prompt: str, endpoint: str = None, key: str = None, model: str = None):
    endpoint = endpoint or NVIDIA_API_URL
    key = key or NVIDIA_API_KEY
    model = model or DEFAULT_MODEL

    if not key or not key.startswith("nvapi-"):
        raise HTTPException(500, "Invalid or missing NVIDIA API key")

    headers = {
        "Authorization": f"Bearer {key}",
        "Content-Type": "application/json",
        "Accept": "application/json"
    }
    data = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "max_tokens": 1024,
        "stream": False
    }

    full_url = f"{endpoint}/chat/completions"
    response = requests.post(full_url, headers=headers, json=data)

    if response.status_code != 200:
        error_text = response.text
        raise HTTPException(500, f"NVIDIA API error: {response.status_code} - {error_text}")

    try:
        return response.json()["choices"][0]["message"]["content"]
    except (KeyError, IndexError):
        raise HTTPException(500, "Unexpected NVIDIA response format")

# ==================== ROUTES ====================
# (keep root, health, admin/setup, auth/register, auth/login, auth/me as before)

# ==================== PLUGINS ====================
# (keep /plugins/add, /plugins/manage, /plugins/delete as before - validation uses NVIDIA format now)

# ==================== PAYMENTS & HISTORY ====================
# (keep as before - dummy process works)

# ==================== AGENTS ====================

@app.get("/api/v1/swarm/agents")
def list_agents():
    # (keep as before)

@app.post("/api/v1/swarm/orchestrate")
def orchestrate(data: OrchestrateRequest, payload = Depends(verify_token)):
    query = data.query
    if not query:
        raise HTTPException(400, "No query provided")

    user = None
    for u in users_db.values():
        if u["email"] == payload["email"]:
            user = u
            break
    if not user:
        raise HTTPException(404, "User not found")

    tier = user.get("tier", "FREE")
    builds_used = user.get("builds_used", 0)
    max_builds = PRICING_TIERS[tier]["builds"]

    if max_builds != -1 and builds_used >= max_builds:
        raise HTTPException(403, f"Build limit reached for {tier} tier")

    user["builds_used"] = builds_used + 1

    # Use user plugin if available, else NVIDIA fallback
    endpoint = NVIDIA_API_URL
    key = NVIDIA_API_KEY
    model = DEFAULT_MODEL
    if user.get("plugins"):
        plugin = user["plugins"][0]
        endpoint = plugin["endpoint"]
        key = plugin["key"]
        model = "custom-model" if plugin["type"] == "vision" else DEFAULT_MODEL

    agents_used = []
    generated_content = ""

    # Simple routing example - expand as needed
    if any(kw in query.lower() for kw in ["landing page", "website", "create", "build"]):
        agents_used.append("Developer")
        agents_db["developer"]["tasks"] += 1
        prompt = f"Generate full {data.platform} code/HTML for: {query}. Use theme: {data.theme}. Make it professional, modern, and complete."
        generated_content = call_llm(prompt, endpoint, key, model)

    # Save to builds folder
    build_id = uuid.uuid4().hex[:8]
    build_dir = f"builds/{build_id}"
    os.makedirs(build_dir, exist_ok=True)
    ext = "html" if data.platform == "web" else "txt"  # or platform-specific
    file_path = f"{build_dir}/index.{ext}"
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(generated_content or "No content generated - check API key/model")

    base_url = "https://yodda.onrender.com"
    generated_url = f"{base_url}/builds/{build_id}/index.{ext}"

    return {
        "status": "success",
        "query": query,
        "response": "Build complete! Your project is ready.",
        "generated_url": generated_url,
        "agents_used": agents_used,
        "builds_remaining": max_builds - user["builds_used"] if max_builds != -1 else "unlimited"
    }

# Keep other routes (debug, themes, etc.) as before

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
